{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train= \"\"\n",
    "p_test= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 237989\n",
      "Number of test images: 2720\n",
      "Number of total images: 240709\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "\n",
    "def count_images(p):\n",
    "    \n",
    "    num_img= 0\n",
    "    \n",
    "    for folder in os.listdir(p):\n",
    "        p_f= p+\"/\"+folder\n",
    "        \n",
    "        if path.isdir(p_f):\n",
    "            for img in os.listdir(p_f):\n",
    "                \n",
    "                num_img+=1\n",
    "    \n",
    "    return num_img\n",
    "            \n",
    "\n",
    "n_train= count_images(p_train)\n",
    "n_test= count_images(p_test)\n",
    "\n",
    "print(f\"Number of train images: {n_train}\")\n",
    "print(f\"Number of test images: {n_test}\")\n",
    "print(f'Number of total images: {n_train+n_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image resolutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image resolutions: \n",
      "{(768, 405): 14873, (768, 432): 223116}\n",
      "\n",
      "Test image resolutions: \n",
      "{(768, 432): 2720}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def count_image_res(p):\n",
    "    \n",
    "    resolutions= dict()\n",
    "    \n",
    "    for folder in os.listdir(p):\n",
    "        p_f= p+\"/\"+folder\n",
    "        \n",
    "        if path.isdir(p_f):\n",
    "            for f in os.listdir(p_f):\n",
    "                    with Image.open(p_f+\"/\"+f) as img:\n",
    "                        img_size= img.size\n",
    "                        \n",
    "                        if img_size in resolutions.keys():\n",
    "                            resolutions[img_size]+=1\n",
    "                        else:\n",
    "                            resolutions[img_size]=1\n",
    "    \n",
    "    return resolutions\n",
    "    \n",
    "train_res= count_image_res(p_train)\n",
    "test_res= count_image_res(p_test)\n",
    "\n",
    "print(\"Train image resolutions: \")\n",
    "pprint(train_res)\n",
    "print(\"\\nTest image resolutions: \")\n",
    "pprint(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked 0 images.\n"
     ]
    }
   ],
   "source": [
    "from os import path as path\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def unpack_bg20k(bg20k):  \n",
    "    n_img= 0\n",
    "    \n",
    "    #bg20k/\n",
    "    for f in os.listdir(bg20k):\n",
    "        \n",
    "        #bg20k/number/BG-20K\n",
    "        f_path= path.join(bg20k, f, 'BG-20K')\n",
    "        \n",
    "        if path.isdir(f_path):\n",
    "            for split in os.listdir(f_path):\n",
    "                \n",
    "                #bg20k/number/BG-20K/train\n",
    "                split_path= path.join(f_path, split)\n",
    "                \n",
    "                #images\n",
    "                if path.isdir(split_path):\n",
    "                    for bg in os.listdir(split_path):  \n",
    "                        \n",
    "                        #bg20k/number/BG-20K/train/bg.jpg\n",
    "                        src= path.join(split_path, bg)\n",
    "                        \n",
    "                        #bg20k/number/BG-20K/bg.jpg\n",
    "                        dest= path.join(bg20k, bg)\n",
    "                        \n",
    "                        shutil.move(src, dest)           \n",
    "                        n_img+=1\n",
    "        \n",
    "        f_num=path.join(bg20k, f)       \n",
    "        \n",
    "        if path.isdir(f_num):\n",
    "            shutil.rmtree(f_num)\n",
    "                                \n",
    "    print(f'Unpacked {n_img} images.')\n",
    "    \n",
    "unpack_bg20k(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "bgs= os.listdir('')\n",
    "print(len(bgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10000 images from /Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import shutil\n",
    "\n",
    "test_input= \"\"\n",
    "train_input= \"\"\n",
    "test_output= \"\"\n",
    "train_output= \"\"\n",
    "\n",
    "def sample_bg10k(src, dest):\n",
    "    \n",
    "    all_images = [f for f in os.listdir(src) if f.endswith('.jpg')]\n",
    "    \n",
    "    sampled_images= sample(all_images, 10000)\n",
    "    train_images= sample(sampled_images, 9000)\n",
    "    test_images= [img for img in sampled_images if  img not in train_images]\n",
    "    \n",
    "    \n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(src, img), os.path.join(dest, 'train', img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(src, img), os.path.join(dest, 'test', img))\n",
    "\n",
    "        \n",
    "    print(f'Sampled 10000 images from {src}')\n",
    "  \n",
    "sample_bg10k('/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k',\n",
    "             '/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    }
   ],
   "source": [
    "p= \"/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k\"\n",
    "\n",
    "train= os.listdir(p)\n",
    "\n",
    "\n",
    "print(len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "videomatte240k_unpacked= \"\"\n",
    "files= os.listdir(videomatte240k_unpacked)\n",
    "print(len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked 0 images.\n",
      "Unpacked 0 images.\n"
     ]
    }
   ],
   "source": [
    "from os import path as path\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def unpack_split(split_path):\n",
    "    \n",
    "    #source    \n",
    "    fgr_path= path.join(split_path, 'fgr')\n",
    "    pha_path= path.join(split_path, 'pha')\n",
    "    \n",
    "    #destination\n",
    "    n_img= 0\n",
    "    \n",
    "    #scenes\n",
    "    for scene_fgr, scene_pha in zip(os.listdir(fgr_path),os.listdir(pha_path)):\n",
    "        scene_fgr_path=path.join(fgr_path, scene_fgr)\n",
    "        scene_pha_path= path.join(pha_path, scene_pha)\n",
    "        \n",
    "        #images\n",
    "        if path.isdir(scene_fgr_path):\n",
    "            for img_fgr, img_pha in zip(os.listdir(scene_fgr_path), os.listdir(scene_pha_path)):\n",
    "                            \n",
    "                name= scene_fgr[-4:]+'_'+img_fgr #provide a unique file_name (scene_img.jpg) \n",
    "                \n",
    "                #copy foreground and alpha matt\n",
    "                shutil.move(path.join(scene_fgr_path, img_fgr), path.join(fgr_path, name))            \n",
    "                shutil.move(path.join(scene_pha_path, img_pha), path.join(pha_path, name))\n",
    "                n_img+=2\n",
    "            os.rmdir(scene_fgr_path)\n",
    "            os.rmdir(scene_pha_path)\n",
    "                                \n",
    "                \n",
    "        \n",
    "    print(f'Unpacked {n_img} images.')\n",
    "        \n",
    "\n",
    "def unpack_videomatte240k(videomatte240k):\n",
    "    videomatte_train= path.join(videomatte240k, \"train\")\n",
    "    videomatte_test= path.join(videomatte240k, \"test\")\n",
    "    \n",
    "    unpack_split(videomatte_train)\n",
    "    unpack_split(videomatte_test)\n",
    "    \n",
    "    \n",
    "\n",
    "videomatte240k= \"\"\n",
    "\n",
    "unpack_videomatte240k(videomatte240k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store']\n",
      ".DS_Store removed.\n",
      "2720\n",
      "2720\n",
      "237989\n",
      "237989\n"
     ]
    }
   ],
   "source": [
    "videomatte240k= \"\"\n",
    "\n",
    "\n",
    "pha_p= path.join(videomatte240k,'test', 'pha')\n",
    "pha_dir= os.listdir(pha_p)\n",
    "deletables= ['.DS_Store']\n",
    "print(deletables)\n",
    "\n",
    "\n",
    "for f in pha_dir:\n",
    "    if f in deletables:\n",
    "        os.remove(path.join(pha_p, f))\n",
    "        print(f'{f} removed.')\n",
    "        \n",
    "print(len(os.listdir(path.join(videomatte240k,'test', 'fgr'))))\n",
    "print(len(os.listdir(path.join(videomatte240k,'test', 'pha'))))\n",
    "print(len(set(os.listdir(path.join(videomatte240k,'train', 'fgr')))))\n",
    "print(len(os.listdir(path.join(videomatte240k,'train', 'pha'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "from os import path\n",
    "\n",
    "def move_splits(split_source: str, split_dest: str, fgrs: list, phas: list):\n",
    "    for fgr, pha in zip(fgrs, phas):\n",
    "        fgr_path= path.join(split_source,\"fgr\", fgr)\n",
    "        pha_path= path.join(split_source, 'pha', pha)\n",
    "        shutil.copy(fgr_path, path.join(split_dest, 'fgr'))\n",
    "        shutil.copy(pha_path, path.join(split_dest, 'pha'))\n",
    "    \n",
    "    print(f'Moved {len(fgrs)} images from {split_source} to {split_dest}')    \n",
    "    \n",
    "def split_dataset(raw_folder, composite_folder):\n",
    "    train_path= path.join(raw_folder, 'train')\n",
    "    \n",
    "    #split train set in train and val sets (equal random state to keep order)\n",
    "    train_fgr, val_fgr= train_test_split(\n",
    "        os.listdir(path.join(train_path, 'fgr')), test_size=3007/237989, random_state=42)\n",
    "    train_pha, val_pha= train_test_split(\n",
    "        os.listdir(path.join(train_path, 'pha')), test_size=3007/237989, random_state=42)\n",
    "    \n",
    "    move_splits(train_path, path.join(composite_folder, 'training', 'train'), train_fgr, train_pha)\n",
    "    move_splits(train_path, path.join(composite_folder, 'training', 'val'), val_fgr, val_pha)\n",
    "    \n",
    "    #just copy test files to dest folder\n",
    "    test_path= path.join(raw_folder, 'test')\n",
    "    test_fgr= os.listdir(path.join(test_path, 'fgr'))\n",
    "    test_pha= os.listdir(path.join(test_path, \"pha\"))\n",
    "    move_splits(test_path, path.join(composite_folder, 'test'), test_fgr, test_pha)\n",
    "    \n",
    "    \n",
    "\n",
    "split_dataset(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3007\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_set(videomatte240k):\n",
    "    #train input\n",
    "    train_folder= os.path.join(videomatte240k, 'train')\n",
    "    train_fgr_folder= os.path.join(train_folder, 'fgr')\n",
    "    train_pha_folder= os.path.join(train_folder, 'pha')\n",
    "    \n",
    "    train_fgr_set= os.listdir(train_fgr_folder)\n",
    "    train_pha_set= os.listdir(train_pha_folder)\n",
    "    \n",
    "    #sample 3007 val images\n",
    "    _,val_fgr_set= train_test_split(train_fgr_set, test_size=3007/237989, random_state= 42)\n",
    "    _,val_pha_set= train_test_split(train_pha_set, test_size=3007/237989, random_state= 42)\n",
    "    \n",
    "    #val output\n",
    "    val_folder= os.path.join(videomatte240k, 'val')\n",
    "    val_fgr_folder= os.path.join(val_folder, 'fgr')\n",
    "    val_pha_folder= os.path.join(val_folder, 'pha')\n",
    "    \n",
    "    \n",
    "    for fgr, pha in zip(val_fgr_set, val_pha_set):\n",
    "        pass\n",
    "    print(len(val_pha_set))\n",
    "\n",
    "\n",
    "split_train_set('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "# Randomly select a background\n",
    "\n",
    "def blend_foreground_with_background(fgr_folder, pha_folder, background_folder, composite_folder):\n",
    "    backgrounds= os.listdir(background_folder)\n",
    "    shuffle(backgrounds)\n",
    "    foregrounds= os.listdir(fgr_folder)\n",
    "    alpha_mattes= os.listdir(pha_folder)\n",
    "     \n",
    "    for i, (fgr_path, pha_path) in enumerate(zip(foregrounds, alpha_mattes)):\n",
    "        bg_path = backgrounds[i%10000]\n",
    "        \n",
    "        bg = Image.open(os.path.join(background_folder, bg_path)).convert(\"RGB\")\n",
    "        fgr= Image.open(os.path.join(fgr_folder, fgr_path)).convert('RGB')\n",
    "        pha= Image.open(os.path.join(pha_folder, pha_path)).convert('L')\n",
    "        \n",
    "        bg= bg.resize(fgr.size, Image.BILINEAR)\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        fgr_np = np.array(fgr)\n",
    "        pha_np = np.array(pha) / 255.0  # Normalize alpha to [0,1]\n",
    "        bg_np = np.array(bg)\n",
    "\n",
    "        # Alpha blending: Composite = Foreground * Alpha + Background * (1 - Alpha)\n",
    "        composite_np = (fgr_np[..., :3] * pha_np[..., None] + bg_np * (1 - pha_np[..., None])).astype(np.uint8)\n",
    "        composite = Image.fromarray(composite_np)\n",
    "        composite_path= os.path.join(composite_folder, fgr_path)\n",
    "        \n",
    "        composite.save(composite_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_foreground_with_background()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
