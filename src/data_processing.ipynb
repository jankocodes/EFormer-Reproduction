{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train= \"\"\n",
    "p_test= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 237989\n",
      "Number of test images: 2720\n",
      "Number of total images: 240709\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "\n",
    "def count_images(p):\n",
    "    \n",
    "    num_img= 0\n",
    "    \n",
    "    for folder in os.listdir(p):\n",
    "        p_f= p+\"/\"+folder\n",
    "        \n",
    "        if path.isdir(p_f):\n",
    "            for img in os.listdir(p_f):\n",
    "                \n",
    "                num_img+=1\n",
    "    \n",
    "    return num_img\n",
    "            \n",
    "\n",
    "n_train= count_images(p_train)\n",
    "n_test= count_images(p_test)\n",
    "\n",
    "print(f\"Number of train images: {n_train}\")\n",
    "print(f\"Number of test images: {n_test}\")\n",
    "print(f'Number of total images: {n_train+n_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image resolutions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image resolutions: \n",
      "{(768, 405): 14873, (768, 432): 223116}\n",
      "\n",
      "Test image resolutions: \n",
      "{(768, 432): 2720}\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def count_image_res(p):\n",
    "    \n",
    "    resolutions= dict()\n",
    "    \n",
    "    for folder in os.listdir(p):\n",
    "        p_f= p+\"/\"+folder\n",
    "        \n",
    "        if path.isdir(p_f):\n",
    "            for f in os.listdir(p_f):\n",
    "                    with Image.open(p_f+\"/\"+f) as img:\n",
    "                        img_size= img.size\n",
    "                        \n",
    "                        if img_size in resolutions.keys():\n",
    "                            resolutions[img_size]+=1\n",
    "                        else:\n",
    "                            resolutions[img_size]=1\n",
    "    \n",
    "    return resolutions\n",
    "    \n",
    "train_res= count_image_res(p_train)\n",
    "test_res= count_image_res(p_test)\n",
    "\n",
    "print(\"Train image resolutions: \")\n",
    "pprint(train_res)\n",
    "print(\"\\nTest image resolutions: \")\n",
    "pprint(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked 0 images.\n"
     ]
    }
   ],
   "source": [
    "from os import path as path\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def unpack_bg20k(bg20k):  \n",
    "    n_img= 0\n",
    "    \n",
    "    #bg20k/\n",
    "    for f in os.listdir(bg20k):\n",
    "        \n",
    "        #bg20k/number/BG-20K\n",
    "        f_path= path.join(bg20k, f, 'BG-20K')\n",
    "        \n",
    "        if path.isdir(f_path):\n",
    "            for split in os.listdir(f_path):\n",
    "                \n",
    "                #bg20k/number/BG-20K/train\n",
    "                split_path= path.join(f_path, split)\n",
    "                \n",
    "                #images\n",
    "                if path.isdir(split_path):\n",
    "                    for bg in os.listdir(split_path):  \n",
    "                        \n",
    "                        #bg20k/number/BG-20K/train/bg.jpg\n",
    "                        src= path.join(split_path, bg)\n",
    "                        \n",
    "                        #bg20k/number/BG-20K/bg.jpg\n",
    "                        dest= path.join(bg20k, bg)\n",
    "                        \n",
    "                        shutil.move(src, dest)           \n",
    "                        n_img+=1\n",
    "        \n",
    "        f_num=path.join(bg20k, f)       \n",
    "        \n",
    "        if path.isdir(f_num):\n",
    "            shutil.rmtree(f_num)\n",
    "                                \n",
    "    print(f'Unpacked {n_img} images.')\n",
    "    \n",
    "unpack_bg20k(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "bgs= os.listdir('')\n",
    "print(len(bgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10000 images from /Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import shutil\n",
    "\n",
    "test_input= \"\"\n",
    "train_input= \"\"\n",
    "test_output= \"\"\n",
    "train_output= \"\"\n",
    "\n",
    "def sample_bg10k(src, dest):\n",
    "    \n",
    "    all_images = [f for f in os.listdir(src) if f.endswith('.jpg')]\n",
    "    \n",
    "    sampled_images= sample(all_images, 10000)\n",
    "    train_images= sample(sampled_images, 9000)\n",
    "    test_images= [img for img in sampled_images if  img not in train_images]\n",
    "    \n",
    "    \n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(src, img), os.path.join(dest, 'train', img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(src, img), os.path.join(dest, 'test', img))\n",
    "\n",
    "        \n",
    "    print(f'Sampled 10000 images from {src}')\n",
    "  \n",
    "sample_bg10k('/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k',\n",
    "             '/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    }
   ],
   "source": [
    "p= \"/Users/jannisschuhmann/Documents/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg20k\"\n",
    "\n",
    "train= os.listdir(p)\n",
    "\n",
    "\n",
    "print(len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2720\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "videomatte240k_unpacked= \"\"\n",
    "files= os.listdir(videomatte240k_unpacked)\n",
    "print(len(files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked 0 images.\n",
      "Unpacked 0 images.\n"
     ]
    }
   ],
   "source": [
    "from os import path as path\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def unpack_split(split_path):\n",
    "    \n",
    "    #source    \n",
    "    fgr_path= path.join(split_path, 'fgr')\n",
    "    pha_path= path.join(split_path, 'pha')\n",
    "    \n",
    "    #destination\n",
    "    n_img= 0\n",
    "    \n",
    "    #scenes\n",
    "    for scene_fgr, scene_pha in zip(os.listdir(fgr_path),os.listdir(pha_path)):\n",
    "        scene_fgr_path=path.join(fgr_path, scene_fgr)\n",
    "        scene_pha_path= path.join(pha_path, scene_pha)\n",
    "        \n",
    "        #images\n",
    "        if path.isdir(scene_fgr_path):\n",
    "            for img_fgr, img_pha in zip(os.listdir(scene_fgr_path), os.listdir(scene_pha_path)):\n",
    "                            \n",
    "                name= scene_fgr[-4:]+'_'+img_fgr #provide a unique file_name (scene_img.jpg) \n",
    "                \n",
    "                #copy foreground and alpha matt\n",
    "                shutil.move(path.join(scene_fgr_path, img_fgr), path.join(fgr_path, name))            \n",
    "                shutil.move(path.join(scene_pha_path, img_pha), path.join(pha_path, name))\n",
    "                n_img+=2\n",
    "            os.rmdir(scene_fgr_path)\n",
    "            os.rmdir(scene_pha_path)\n",
    "                                \n",
    "                \n",
    "        \n",
    "    print(f'Unpacked {n_img} images.')\n",
    "        \n",
    "\n",
    "def unpack_videomatte240k(videomatte240k):\n",
    "    videomatte_train= path.join(videomatte240k, \"train\")\n",
    "    videomatte_test= path.join(videomatte240k, \"test\")\n",
    "    \n",
    "    unpack_split(videomatte_train)\n",
    "    unpack_split(videomatte_test)\n",
    "    \n",
    "    \n",
    "\n",
    "videomatte240k= \"\"\n",
    "\n",
    "unpack_videomatte240k(videomatte240k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store']\n",
      ".DS_Store removed.\n",
      "2720\n",
      "2720\n",
      "237989\n",
      "237989\n"
     ]
    }
   ],
   "source": [
    "videomatte240k= \"\"\n",
    "\n",
    "\n",
    "pha_p= path.join(videomatte240k,'test', 'pha')\n",
    "pha_dir= os.listdir(pha_p)\n",
    "deletables= ['.DS_Store']\n",
    "print(deletables)\n",
    "\n",
    "\n",
    "for f in pha_dir:\n",
    "    if f in deletables:\n",
    "        os.remove(path.join(pha_p, f))\n",
    "        print(f'{f} removed.')\n",
    "        \n",
    "print(len(os.listdir(path.join(videomatte240k,'test', 'fgr'))))\n",
    "print(len(os.listdir(path.join(videomatte240k,'test', 'pha'))))\n",
    "print(len(set(os.listdir(path.join(videomatte240k,'train', 'fgr')))))\n",
    "print(len(os.listdir(path.join(videomatte240k,'train', 'pha'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "from os import path\n",
    "\n",
    "def move_splits(split_source: str, split_dest: str, fgrs: list, phas: list):\n",
    "    for fgr, pha in zip(fgrs, phas):\n",
    "        fgr_path= path.join(split_source,\"fgr\", fgr)\n",
    "        pha_path= path.join(split_source, 'pha', pha)\n",
    "        shutil.copy(fgr_path, path.join(split_dest, 'fgr'))\n",
    "        shutil.copy(pha_path, path.join(split_dest, 'pha'))\n",
    "    \n",
    "    print(f'Moved {len(fgrs)} images from {split_source} to {split_dest}')    \n",
    "    \n",
    "def split_dataset(raw_folder, composite_folder):\n",
    "    train_path= path.join(raw_folder, 'train')\n",
    "    \n",
    "    #split train set in train and val sets (equal random state to keep order)\n",
    "    train_fgr, val_fgr= train_test_split(\n",
    "        os.listdir(path.join(train_path, 'fgr')), test_size=3007/237989, random_state=42)\n",
    "    train_pha, val_pha= train_test_split(\n",
    "        os.listdir(path.join(train_path, 'pha')), test_size=3007/237989, random_state=42)\n",
    "    \n",
    "    move_splits(train_path, path.join(composite_folder, 'training', 'train'), train_fgr, train_pha)\n",
    "    move_splits(train_path, path.join(composite_folder, 'training', 'val'), val_fgr, val_pha)\n",
    "    \n",
    "    #just copy test files to dest folder\n",
    "    test_path= path.join(raw_folder, 'test')\n",
    "    test_fgr= os.listdir(path.join(test_path, 'fgr'))\n",
    "    test_pha= os.listdir(path.join(test_path, \"pha\"))\n",
    "    move_splits(test_path, path.join(composite_folder, 'test'), test_fgr, test_pha)\n",
    "    \n",
    "    \n",
    "\n",
    "split_dataset(\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 3007 images into /Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD/val/fgr\n",
      "Sampled 3007 images into /Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD/val/pha\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "def split_train_set(videomatte240k):\n",
    "    #train input\n",
    "    train_fgr_folder= os.path.join(videomatte240k, 'train', 'fgr')\n",
    "    train_pha_folder= os.path.join(videomatte240k, 'train', 'pha')\n",
    "    \n",
    "    train_fgr_set= os.listdir(train_fgr_folder)\n",
    "    train_pha_set= os.listdir(train_pha_folder)\n",
    "    \n",
    "    #sample 3007 val images (fgr and pha names are equal)\n",
    "    _,val_set= train_test_split(train_fgr_set, test_size=3007/237989, random_state= 42)\n",
    "    \n",
    "    #val output\n",
    "    val_fgr_folder= os.path.join(videomatte240k, 'val', 'fgr')\n",
    "    val_pha_folder= os.path.join(videomatte240k,'val', 'pha')\n",
    "\n",
    "    \n",
    "    #move fgr and pha\n",
    "    for name in val_set:\n",
    "        shutil.move(os.path.join(train_fgr_folder,name), os.path.join(val_fgr_folder, name))\n",
    "        shutil.move(os.path.join(train_pha_folder, name),  os.path.join(val_pha_folder, name))\n",
    "    \n",
    "    print(f'Sampled 3007 images into {val_fgr_folder}')\n",
    "    print(f'Sampled 3007 images into {val_pha_folder}')\n",
    "        \n",
    "        \n",
    "\n",
    "split_train_set('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from random import shuffle\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "\n",
    "# Randomly select a background\n",
    "\n",
    "def blend_foreground_with_background(split_src, background_folder, split_dest):\n",
    "    \n",
    "    backgrounds= [f for f in os.listdir(background_folder) if f.endswith('.jpg')]\n",
    "    \n",
    "    shuffle(backgrounds)\n",
    "    \n",
    "    fgr_folder= os.path.join(split_src, 'fgr')\n",
    "    pha_folder= os.path.join(split_src, 'pha')\n",
    "    \n",
    "    foregrounds= [f for f in os.listdir(fgr_folder) if f.endswith('.jpg')]\n",
    "    alpha_mattes= [f for f in os.listdir(pha_folder) if f.endswith('.jpg')]\n",
    "     \n",
    "    with alive_bar(len(foregrounds), force_tty= True) as bar:\n",
    "        \n",
    "        for i, (fgr_path, pha_path) in enumerate(zip(foregrounds, alpha_mattes)):\n",
    "            composite_path= os.path.join(split_dest,'composites', fgr_path)\n",
    "\n",
    "            if os.path.exists(composite_path):\n",
    "                bar()\n",
    "                continue\n",
    "                \n",
    "            bg_path = backgrounds[i%len(backgrounds)]\n",
    "        \n",
    "            bg = Image.open(os.path.join(background_folder, bg_path)).convert(\"RGB\")\n",
    "            fgr= Image.open(os.path.join(fgr_folder, fgr_path)).convert('RGB')\n",
    "            pha= Image.open(os.path.join(pha_folder, pha_path)).convert('L')\n",
    "            \n",
    "            #resize bg to fgr_size in order to avoid pha mismatch after composition\n",
    "            bg= bg.resize(fgr.size, Image.BILINEAR)\n",
    "\n",
    "            # Convert to NumPy arrays\n",
    "            fgr_np = np.array(fgr)\n",
    "            pha_np = np.array(pha) / 255.0  # Normalize alpha to [0,1]\n",
    "            bg_np = np.array(bg)\n",
    "\n",
    "            # Alpha blending: Composite = Foreground * Alpha + Background * (1 - Alpha)\n",
    "            composite_np = (fgr_np[..., :3] * pha_np[..., None] + bg_np * (1 - pha_np[..., None])).astype(np.uint8)\n",
    "            composite = Image.fromarray(composite_np)\n",
    "            composite_path= os.path.join(split_dest,'composites', fgr_path)\n",
    "            \n",
    "            composite.save(composite_path)\n",
    "            shutil.copy(os.path.join(pha_folder, pha_path), os.path.join(split_dest, 'pha', pha_path))\n",
    "            \n",
    "            if i%1000==0:\n",
    "                bar(1000)\n",
    "            \n",
    "        print(f'Composed {len(foregrounds)} images and moved them to {split_dest}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|███████████▌⚠︎                           | (!) 67260/234982 [29%] in 2:41.7 (416\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mblend_foreground_with_background\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg10k/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/composite_dataset/train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 50\u001b[0m, in \u001b[0;36mblend_foreground_with_background\u001b[0;34m(split_src, background_folder, split_dest)\u001b[0m\n\u001b[1;32m     47\u001b[0m composite \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(composite_np)\n\u001b[1;32m     48\u001b[0m composite_path\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(split_dest,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomposites\u001b[39m\u001b[38;5;124m'\u001b[39m, fgr_path)\n\u001b[0;32m---> 50\u001b[0m \u001b[43mcomposite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomposite_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopy(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pha_folder, pha_path), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(split_dest, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpha\u001b[39m\u001b[38;5;124m'\u001b[39m, pha_path))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/eformer_env/lib/python3.9/site-packages/PIL/Image.py:2605\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2602\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2605\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/eformer_env/lib/python3.9/site-packages/PIL/JpegImagePlugin.py:843\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;66;03m# The EXIF info needs to be written as one block, + APP1, + one spare byte.\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;66;03m# Ensure that our buffer is big enough. Same with the icc_profile block.\u001b[39;00m\n\u001b[1;32m    841\u001b[0m     bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(bufsize, \u001b[38;5;28mlen\u001b[39m(exif) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(extra) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 843\u001b[0m \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/eformer_env/lib/python3.9/site-packages/PIL/ImageFile.py:556\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    554\u001b[0m     fh \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mfileno()\n\u001b[1;32m    555\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 556\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    558\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[38;5;28;01mNone\u001b[39;00m, exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/eformer_env/lib/python3.9/site-packages/PIL/ImageFile.py:591\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;66;03m# slight speedup: compress to real file object\u001b[39;00m\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m fh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m         errcode \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _get_oserror(errcode, encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "blend_foreground_with_background('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/VideoMatte240K_JPEG_SD/train',\n",
    "                                  '/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/raw/bg10k/train',\n",
    "                                  '/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/composite_dataset/train'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67531\n",
      "67532\n"
     ]
    }
   ],
   "source": [
    "com= os.listdir('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/composite_dataset/train/composites')\n",
    "pha= os.listdir('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/composite_dataset/train/pha')\n",
    "missing=[img for img in com if img not in pha]\n",
    "print(len(pha))\n",
    "print(len(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0024_00155.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shutil.copy(os.path.join(pha_folder, pha_path), os.path.join(split_dest, 'pha', pha_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56851\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(len(os.listdir('/Users/jannisschuhmann/Uni/Semester5/ProjectCVPR/EFormer-Reproduction/datasets/composite_dataset/train/pha')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eformer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
